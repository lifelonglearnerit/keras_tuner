{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lifelonglearnerit/keras_tuner/blob/main/keras_tuner_balanced_batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_YlUKZaW_n_"
      },
      "source": [
        "# Balanced Batch Generator for Tensorflow models\n",
        "Exploration of the applications of balanced batch generator to imbalanced classfication problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ3iNrq8W_oH"
      },
      "outputs": [],
      "source": [
        "# eda necessary \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import datetime as dt\n",
        "import re \n",
        "import random \n",
        "from ipywidgets import widgets\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "\n",
        "# modeling \n",
        "import numpy\n",
        "import matplotlib.pyplot  as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import random \n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from numpy import average\n",
        "from numpy import where\n",
        "from collections import Counter \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.metrics import Recall\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.metrics import TruePositives\n",
        "from tensorflow.keras.metrics import TrueNegatives\n",
        "from tensorflow.keras.metrics import FalsePositives\n",
        "from tensorflow.keras.metrics import FalseNegatives\n",
        "from tensorflow.keras.metrics import PrecisionAtRecall\n",
        "from tensorflow.keras.metrics import SensitivityAtSpecificity\n",
        "from tensorflow.keras.metrics import SpecificityAtSensitivity\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import Hyperband\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from keras_tuner.tuners import BayesianOptimization\n",
        "from keras_tuner import Objective, HyperParameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyN87yQ3W_oK"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "# parameters template with default settings \n",
        "PARAMETERS = {\n",
        "    'RandomSearch': {\n",
        "                    'hypermodel': None,\n",
        "                    'objective': None,\n",
        "                    'max_trials': 10,\n",
        "                    'seed': None,\n",
        "                    'project_name': None\n",
        "        },\n",
        "        \n",
        "    'Hyperband': {\n",
        "                    'hypermodel': None, \n",
        "                    'objective': None, \n",
        "                    'max_epochs': 100, \n",
        "                    'factor': 3, \n",
        "                    'hyperband_iterations': 1, \n",
        "                    'seed': None, \n",
        "                    'project_name': None\n",
        "        },\n",
        "    'BayesianOptimization': {\n",
        "                    'hypermodel':None,\n",
        "                    'objective':None,\n",
        "                    'max_trials':10,\n",
        "                    'num_initial_points':2,\n",
        "                    'alpha':0.0001,\n",
        "                    'beta':2.6,\n",
        "                    'seed':None,\n",
        "                    'project_name': None\n",
        "        },\n",
        "\n",
        "                 \n",
        "    'search_param': {\n",
        "            'x':None,\n",
        "            'y':None,\n",
        "            'batch_size':None,\n",
        "            'epochs':1,\n",
        "            'verbose':'auto',\n",
        "            'callbacks': None,\n",
        "            'validation_split': 0.0,\n",
        "            'validation_data':None,\n",
        "            'shuffle':True,\n",
        "            'class_weight':None,\n",
        "            'sample_weight':None,\n",
        "            'initial_epoch':0,\n",
        "            'steps_per_epoch':None,\n",
        "            'validation_steps':None,\n",
        "            'validation_batch_size':None,\n",
        "            'validation_freq':1,\n",
        "            'max_queue_size':10,\n",
        "            'workers': 1,\n",
        "            'use_multiprocessing': False\n",
        "        },\n",
        "    \n",
        "    'return_param': {\n",
        "        'num_trials': 1,\n",
        "        'num_models': 5,\n",
        "        'num_trials_summary': 5\n",
        "        }\n",
        "\n",
        "    }\n",
        "def make_parameters():\n",
        "    return copy.deepcopy(PARAMETERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8c9Dc68W_oL"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from functools import wraps\n",
        "\n",
        "def timeit(f):\n",
        "    @wraps(f)\n",
        "    def wrapper(*args, **kwds):\n",
        "        start_time = time.time()\n",
        "        result = f(*args, **kwds)\n",
        "        elapsed_time = time.time() - start_time\n",
        "        print(f\"Elapsed computation time: {elapsed_time:.3f} secs\")\n",
        "        return (elapsed_time, result)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "def prepare_data(data: pd.DataFrame,\n",
        "                 test_size: float):\n",
        "    \n",
        "    last_col = list(data.columns)[-1]\n",
        "    features = data.drop(labels=(last_col), axis=1)\n",
        "    labels   = data[last_col]\n",
        "    \n",
        "    X_train_all, X_val_all, y_train, y_val  = train_test_split(\n",
        "        features, labels, test_size=test_size, random_state=42, \n",
        "        stratify=labels\n",
        "        )\n",
        "    \n",
        "    return [X_train_all, X_val_all, y_train, y_val, features, labels]\n",
        "\n",
        "def transform_data(features, labels): \n",
        "    cat_cols = features.select_dtypes(include=['object', 'bool']).columns\n",
        "    num_cols = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "    labels = LabelEncoder().fit_transform(labels)\n",
        "    preprocesor = ColumnTransformer(\n",
        "        [('c', OneHotEncoder(), cat_cols), \n",
        "         ('s', StandardScaler(), num_cols)],\n",
        "         remainder=\"passthrough\",\n",
        "         sparse_threshold=0\n",
        "        )\n",
        "    features = preprocesor.fit_transform(features)\n",
        "    return features, labels \n",
        "\n",
        "def weight_heuristic(training_labels: numpy.array) -> dict: \n",
        "    weights = dict()\n",
        "    \"\"\"Heuristic for generating class weights for imbalanced classification\n",
        "    based on : https://gking.harvard.edu/files/0s.pdf\n",
        "    class weight = number of rows / (number of classes * number of class members)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    training_labels : numpy.arrary\n",
        "        An array of labels for binary classification problem\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary with weights for each class:\n",
        "        {0: weight, 1: weight}\n",
        "    \"\"\"\n",
        "    n_samples = training_labels.shape[0]\n",
        "    n_neg_samp, n_pos_samp = np.bincount(training_labels)\n",
        "    \n",
        "    weights[0] = n_samples / (2 * n_neg_samp)\n",
        "    weights[1] = n_samples / (2 * n_pos_samp)\n",
        "\n",
        "    return weights\n",
        "    \n",
        "\n",
        "\n",
        "def dynamic_builder(hp: HyperParameters) -> Model:\n",
        "    METRICS = [\n",
        "        AUC(curve=\"ROC\", name=\"auc\"),\n",
        "        AUC(curve=\"PR\", name=\"pr\"),\n",
        "        Precision(name='precision'),\n",
        "        Recall(name='recall'),\n",
        "        TruePositives(name='tp'),\n",
        "        FalsePositives(name='fp'),\n",
        "        TrueNegatives(name='tn'),\n",
        "        FalseNegatives(name='fn'),\n",
        "            ]\n",
        "\n",
        "    \n",
        "    model = keras.Sequential()\n",
        "\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
        "        model.add(\n",
        "            keras.layers.Dense(\n",
        "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "            )\n",
        "        )\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(keras.layers.Dropout(rate=hp.Choice(\"drop\", [0.2, 0.3, 0.5])))\n",
        "        \n",
        "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "    \n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
        "    \n",
        "    optimizers_dict = {\n",
        "        \"Adam\":    Adam(learning_rate=learning_rate, name=\"Adam\"),\n",
        "        \"SGD\":     SGD(learning_rate=learning_rate, name=\"SGD\"),\n",
        "        \"Adagrad\": Adagrad(learning_rate=learning_rate, name=\"Adagrad\")\n",
        "        }\n",
        "    \n",
        "    hp_optimizers = hp.Choice('optimizer', [\"Adam\", \"Adagrad\"])\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer=optimizers_dict[hp_optimizers],\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=METRICS,\n",
        "        )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "@timeit\n",
        "def multi_tuner(tuner: 'str',\n",
        "                params: dict) -> tuple: \n",
        "    \"\"\"Initiates search for Hyperparameters for neural network \n",
        "    with specified search algorithm and arguments \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tuner : str\n",
        "        A string denoting name of the search algorithm which \n",
        "        will be used\n",
        "    params: dict\n",
        "        A dictionary with arguments for search algoritm and \n",
        "        keras\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple with parameters in format:\n",
        "        (best hyperparameters, list(specified number of best models))\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    dict_tuners = {\n",
        "        'RandomSearch'        : kt.RandomSearch(**params['RandomSearch']),\n",
        "        'Hyperband'           : kt.Hyperband(**params['Hyperband']),\n",
        "        'BayesianOptimization': kt.BayesianOptimization(**params['BayesianOptimization'])\n",
        "    }\n",
        "    \n",
        "\n",
        "    multi_tuner   = dict_tuners[tuner]\n",
        "    \n",
        "    \n",
        "    if type(params['search_param']) == tuple:\n",
        "        balanced_generator = params['search_param'][0]\n",
        "        print('balanced_generator', balanced_generator)\n",
        "        args_parameters    = params['search_param'][1]\n",
        "        print('args_parameters', args_parameters)\n",
        "        multi_search  = multi_tuner.search(balanced_generator, **args_parameters)\n",
        "    else: \n",
        "        print('dlaczego tu FFS')\n",
        "        multi_search  = multi_tuner.search(**params['search_param'])\n",
        "        \n",
        "    multi_best_hp = multi_tuner.get_best_hyperparameters(\n",
        "                                    num_trials=params['return_param'].get('num_trials', 1))[0]\n",
        "    multi_best_models = multi_tuner.get_best_models(\n",
        "                                    num_models=params['return_param'].get('num_models', 5))\n",
        "    \n",
        "\n",
        "    if params['return_param'].get('num_trials_summary', 0) > 0:\n",
        "        multi_tuner.results_summary(num_trials=params.get('num_trials_summary', 0))\n",
        "    \n",
        "    \n",
        "    return multi_best_hp, multi_best_models\n",
        "\n",
        "\n",
        "\n",
        "def generator_to_search(parameters: tuple) -> tuple:\n",
        "    \"\"\"Prepares tuple with arguments for non-keyword and keyword \n",
        "    parameters of keras.tuner.search method \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    parameters : tuple\n",
        "        A tuple with following order:\n",
        "        (generator, epochs, steps_per_epoch, class_weight)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple\n",
        "        A tuple with parameters in format:\n",
        "        (non-keyword, {keyword})\n",
        "    \"\"\"\n",
        "    \n",
        "    generator       = parameters[0]\n",
        "    epochs     = parameters[1]\n",
        "    steps_per_epoch = parameters[2]\n",
        "    class_weight    = parameters[3]\n",
        "    \n",
        "    return (\n",
        "        generator, \n",
        "            {\n",
        "            'epochs': epochs,\n",
        "            'steps_per_epoch': steps_per_epoch,\n",
        "            'class_weight': class_weight,\n",
        "            }\n",
        "        )\n",
        "\n",
        "@timeit\n",
        "def run_multi_tuners(tuners: list, parameters: dict) -> dict:\n",
        "    \"\"\"Iteratively invokes multituner_function for different \n",
        "    search algorithms\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tuners : list\n",
        "        A list of the search algorithm names \n",
        "    parameters : dict\n",
        "        A dictionary containing parameters necessary to start \n",
        "        tuning process of keras tuner \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        a dictionary of results from multi_tuner \n",
        "        key: name of the algoirthm\n",
        "        value: (time, (time {ulti_best_hp, multi_best_models}))\n",
        "    \"\"\"\n",
        "    results = dict()\n",
        "    for alg in tuners: \n",
        "        print(f'Hyperparameters search with {alg} initiated')\n",
        "        results[alg] = multi_tuner(alg, parameters)\n",
        "        print(results[alg])\n",
        "    return results \n",
        "\n",
        "\n",
        "def multi_results(tuners: list, results: tuple):\n",
        "    \"\"\"Prints results of the muli_tuner function\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tuners : list\n",
        "        A list of the search algorithm names \n",
        "    results : tuple\n",
        "        results from multi_tuner function \n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    print(f'Hyperparameter search for {tuners}\\ncompleted in {results[0]} sec')\n",
        "    for model in tuners:\n",
        "        print(f'\\n========= {model} =========')\n",
        "        print(f'Search completed in {results[1][model][0]} sec')\n",
        "        for hp, val in results[1][model][1][0].values.items():\n",
        "            \n",
        "            print(f'{hp}: {val}')\n",
        "            \n",
        "            \n",
        "def best_models_retraining(\n",
        "                multituner_results: tuple,\n",
        "                train_data: list,\n",
        "                param: dict\n",
        "                ): \n",
        "    \n",
        "    trained_models   = dict()\n",
        "    retrained_models = dict()\n",
        "    \n",
        "    mtr = multituner_results \n",
        "    search_algorithms_names = mtr[1].keys()\n",
        "    \n",
        "    for idx, algorithm in enumerate(search_algorithms_names):\n",
        "        print(f'Training of the model with best HP from {algorithm} search')\n",
        "        best_model = mtr[1][algorithm][1][1][0]\n",
        "        print(best_model)\n",
        "        print(train_data[0].shape)\n",
        "        print(train_data[1].shape)\n",
        "        if param.get('generator', 0) != 0:\n",
        "            generator = param.get('generator', 0),\n",
        "            history = best_model.fit(\n",
        "                                *generator,\n",
        "                                epochs=param.get('epochs', 50), \n",
        "                                verbose=param.get('verbose', 2), \n",
        "                                batch_size=param.get('batch_size', 32),\n",
        "                                validation_split=param.get('validation_split', 0.1),\n",
        "                                steps_per_epoch=param.get('steps_per_epoch', 7)\n",
        "                                )           \n",
        "        else:\n",
        "            history = best_model.fit(\n",
        "                                train_data[0], \n",
        "                                train_data[1], \n",
        "                                epochs=param.get('epochs', 50), \n",
        "                                verbose=param.get('verbose', 2), \n",
        "                                batch_size=param.get('batch_size', 32),\n",
        "                                validation_split=param.get('validation_split', 0.1)\n",
        "                                )\n",
        "        \n",
        "        metric = param.get('metric', 'pr') \n",
        "        best_epoch = history.history[metric].index(max(history.history[metric])) + 1\n",
        "        print(f'Model #{idx} fit finished with best {metric}: {max(history.history[metric])} in epoch: {best_epoch}\\n')\n",
        "        trained_models[idx] = [best_model, history, best_epoch]\n",
        "    \n",
        "    for elements in trained_models.items():\n",
        "        print(f'Retraining of the model #{elements[0]}')\n",
        "        model = elements[1][0]\n",
        "        best_train_epoch = elements[1][2]\n",
        "        retrained_history = model.fit(\n",
        "                                train_data[0], \n",
        "                                train_data[1], \n",
        "                                epochs=best_train_epoch,\n",
        "                                verbose=param.get('verbose', 2), \n",
        "                                batch_size=param.get('batch_size', 32)\n",
        "                               )\n",
        "        retrained_models[elements[0]] = [model, retrained_history]\n",
        "    \n",
        "    return trained_models, retrained_models\n",
        "        \n",
        "    \n",
        "def model_evaluate(model: keras.Model, \n",
        "                   test_data: list,\n",
        "                   params: dict) -> dict:\n",
        "    print('Evaluating on test data')\n",
        "    batch = params.get('batch_size', 32)\n",
        "    \n",
        "    results = model.evaluate(\n",
        "                    test_data[0], \n",
        "                    test_data[1], \n",
        "                    batch_size=batch\n",
        "                    )\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jW_kL3JW_oO"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "\n",
        "# generate dataset\n",
        "X, y = make_classification(n_samples=100000, n_features=2, n_redundant=0,\n",
        "n_clusters_per_class=2, weights=[0.95], flip_y=0, random_state=84)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw919UG0W_oO",
        "outputId": "5b50a718-881a-4677-d355-13f0c9e3c877"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({0: 95000, 1: 5000})\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline \n",
        "from collections import Counter\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "\n",
        "# summarize class distribution\n",
        "\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# scatter plot of examples by class label\n",
        "for label, _ in counter.items():\n",
        "    row_ix = where(y == label)[0]\n",
        "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhuUs8yiW_oQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXofvEkbW_oQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmnsfvMgW_oR"
      },
      "outputs": [],
      "source": [
        "from imblearn.keras import balanced_batch_generator, BalancedBatchGenerator\n",
        "from imblearn.under_sampling import NearMiss\n",
        "# train_labels_g = tensorflow.keras.utils.to_categorical(train_labels, 2)\n",
        "training_generator, steps_epoch = balanced_batch_generator(\n",
        "    X_train, y_train, sampler=NearMiss(), batch_size=100, random_state=42\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzAY0w95W_oR"
      },
      "outputs": [],
      "source": [
        "# copy of the parameter template \n",
        "multi_parameters = make_parameters()\n",
        "\n",
        "\n",
        "# early stopping instance\n",
        "early_stop = EarlyStopping(monitor='pr',patience=5)\n",
        "\n",
        "# defining parameters of the RandomSearch tuner \n",
        "multi_parameters['RandomSearch']['hypermodel']   = dynamic_builder\n",
        "multi_parameters['RandomSearch']['objective']    = Objective('pr', direction='max')\n",
        "multi_parameters['RandomSearch']['max_trials']   = 20\n",
        "multi_parameters['RandomSearch']['seed']         = 42\n",
        "multi_parameters['RandomSearch']['project_name'] = 'change1'\n",
        "multi_parameters['RandomSearch']['directory']    = \"change_\"\n",
        "                         \n",
        "# defining parameters of the Hyperband tuner \n",
        "multi_parameters['Hyperband']['hypermodel']   = dynamic_builder\n",
        "multi_parameters['Hyperband']['objective']    = Objective('pr', direction='max')\n",
        "multi_parameters['Hyperband']['max_epochs']   = 20\n",
        "multi_parameters['Hyperband']['seed']         = 42\n",
        "multi_parameters['Hyperband']['project_name'] = 'change2'\n",
        "multi_parameters['Hyperband']['directory']    = \"change_\"\n",
        "\n",
        "# defining parameters of the BayesianOptimization tuner \n",
        "multi_parameters['BayesianOptimization']['hypermodel']   = dynamic_builder\n",
        "multi_parameters['BayesianOptimization']['objective']    = Objective('pr', direction='max')\n",
        "multi_parameters['BayesianOptimization']['max_trials']   = 20\n",
        "multi_parameters['BayesianOptimization']['seed']         = 42\n",
        "multi_parameters['BayesianOptimization']['project_name'] = 'change3'\n",
        "multi_parameters['BayesianOptimization']['directory']    = \"change_\"\n",
        "\n",
        "# defining search parameters \n",
        "bb_generator = training_generator\n",
        "epochs = 50\n",
        "steps_per_epoch = 7\n",
        "class_weight = None\n",
        "generator_search = (bb_generator, epochs, steps_per_epoch, class_weight)\n",
        "multi_parameters['search_param'] = generator_to_search(generator_search)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDClIcH-W_oS",
        "outputId": "b4e826a1-1f70-4685-d37a-c90a1576a705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 05s]\n",
            "pr: 0.9868608713150024\n",
            "\n",
            "Best pr So Far: 0.9878972172737122\n",
            "Total elapsed time: 00h 02m 30s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Results summary\n",
            "Results in change_\\change3\n",
            "Showing 0 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x0000024BC0E7FFA0>\n",
            "Elapsed computation time: 151.480 secs\n",
            "(151.47964215278625, (<keras_tuner.engine.hyperparameters.HyperParameters object at 0x0000024BC6353370>, [<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC21AFE80>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC4D35310>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC3A62730>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC6546310>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BCB6B0EE0>]))\n",
            "Elapsed computation time: 358.352 secs\n"
          ]
        }
      ],
      "source": [
        "tuners_list = ['RandomSearch', 'Hyperband', 'BayesianOptimization']\n",
        "multituners_results = run_multi_tuners(tuners_list, multi_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrZVU27sW_oT",
        "outputId": "e833a745-cbb9-48f0-9b17-6cab1521d41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyperparameter search for ['RandomSearch', 'Hyperband', 'BayesianOptimization']\n",
            "completed in 358.35162568092346 sec\n",
            "\n",
            "========= RandomSearch =========\n",
            "Search completed in 99.91610264778137 sec\n",
            "num_layers: 3\n",
            "units_0: 224\n",
            "activation: relu\n",
            "dropout: False\n",
            "lr: 0.0025890919266874407\n",
            "optimizer: Adagrad\n",
            "units_1: 512\n",
            "units_2: 128\n",
            "units_3: 320\n",
            "drop: 0.3\n",
            "\n",
            "========= Hyperband =========\n",
            "Search completed in 106.95476770401001 sec\n",
            "num_layers: 2\n",
            "units_0: 384\n",
            "activation: tanh\n",
            "dropout: False\n",
            "lr: 0.0036569295366168696\n",
            "optimizer: Adagrad\n",
            "units_1: 192\n",
            "units_2: 416\n",
            "units_3: 256\n",
            "drop: 0.2\n",
            "tuner/epochs: 20\n",
            "tuner/initial_epoch: 7\n",
            "tuner/bracket: 1\n",
            "tuner/round: 1\n",
            "tuner/trial_id: 0019\n",
            "\n",
            "========= BayesianOptimization =========\n",
            "Search completed in 151.47964215278625 sec\n",
            "num_layers: 5\n",
            "units_0: 32\n",
            "activation: relu\n",
            "dropout: True\n",
            "lr: 0.0025278863265980945\n",
            "optimizer: Adam\n",
            "units_1: 512\n",
            "units_2: 32\n",
            "units_3: 512\n",
            "drop: 0.2\n",
            "units_4: 352\n"
          ]
        }
      ],
      "source": [
        "multi_results(tuners_list, multituners_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4NXF7WdW_oT",
        "outputId": "1758583a-e017-43be-c70c-dbc5b22ac6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training of the model with best HP from RandomSearch search\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC6192B50>\n",
            "(80000, 2)\n",
            "(80000,)\n",
            "Epoch 1/50\n",
            "7/7 - 2s - loss: 0.4714 - auc: 0.9676 - pr: 0.9749 - precision: 0.9962 - recall: 0.7551 - tp: 259.0000 - fp: 1.0000 - tn: 356.0000 - fn: 84.0000\n",
            "Epoch 2/50\n",
            "7/7 - 0s - loss: 0.4624 - auc: 0.9712 - pr: 0.9797 - precision: 1.0000 - recall: 0.7529 - tp: 259.0000 - fp: 0.0000e+00 - tn: 356.0000 - fn: 85.0000\n",
            "Epoch 3/50\n",
            "7/7 - 0s - loss: 0.4522 - auc: 0.9695 - pr: 0.9781 - precision: 1.0000 - recall: 0.7880 - tp: 275.0000 - fp: 0.0000e+00 - tn: 351.0000 - fn: 74.0000\n",
            "Epoch 4/50\n",
            "7/7 - 0s - loss: 0.4484 - auc: 0.9644 - pr: 0.9780 - precision: 1.0000 - recall: 0.8028 - tp: 285.0000 - fp: 0.0000e+00 - tn: 345.0000 - fn: 70.0000\n",
            "Epoch 5/50\n",
            "7/7 - 0s - loss: 0.4495 - auc: 0.9596 - pr: 0.9705 - precision: 1.0000 - recall: 0.7568 - tp: 252.0000 - fp: 0.0000e+00 - tn: 367.0000 - fn: 81.0000\n",
            "Epoch 6/50\n",
            "7/7 - 0s - loss: 0.4315 - auc: 0.9713 - pr: 0.9821 - precision: 1.0000 - recall: 0.8189 - tp: 294.0000 - fp: 0.0000e+00 - tn: 341.0000 - fn: 65.0000\n",
            "Epoch 7/50\n",
            "7/7 - 0s - loss: 0.4206 - auc: 0.9792 - pr: 0.9862 - precision: 1.0000 - recall: 0.8164 - tp: 289.0000 - fp: 0.0000e+00 - tn: 346.0000 - fn: 65.0000\n",
            "Epoch 8/50\n",
            "7/7 - 0s - loss: 0.4255 - auc: 0.9628 - pr: 0.9760 - precision: 1.0000 - recall: 0.7920 - tp: 278.0000 - fp: 0.0000e+00 - tn: 349.0000 - fn: 73.0000\n",
            "Epoch 9/50\n",
            "7/7 - 0s - loss: 0.4239 - auc: 0.9674 - pr: 0.9765 - precision: 0.9962 - recall: 0.7443 - tp: 259.0000 - fp: 1.0000 - tn: 351.0000 - fn: 89.0000\n",
            "Epoch 10/50\n",
            "7/7 - 0s - loss: 0.4420 - auc: 0.9485 - pr: 0.9642 - precision: 0.9962 - recall: 0.7472 - tp: 263.0000 - fp: 1.0000 - tn: 347.0000 - fn: 89.0000\n",
            "Epoch 11/50\n",
            "7/7 - 0s - loss: 0.4029 - auc: 0.9793 - pr: 0.9849 - precision: 0.9932 - recall: 0.8056 - tp: 290.0000 - fp: 2.0000 - tn: 338.0000 - fn: 70.0000\n",
            "Epoch 12/50\n",
            "7/7 - 0s - loss: 0.4324 - auc: 0.9509 - pr: 0.9658 - precision: 0.9962 - recall: 0.7361 - tp: 265.0000 - fp: 1.0000 - tn: 339.0000 - fn: 95.0000\n",
            "Epoch 13/50\n",
            "7/7 - 0s - loss: 0.3844 - auc: 0.9748 - pr: 0.9799 - precision: 1.0000 - recall: 0.8080 - tp: 261.0000 - fp: 0.0000e+00 - tn: 377.0000 - fn: 62.0000\n",
            "Epoch 14/50\n",
            "7/7 - 0s - loss: 0.3911 - auc: 0.9728 - pr: 0.9811 - precision: 1.0000 - recall: 0.8079 - tp: 286.0000 - fp: 0.0000e+00 - tn: 346.0000 - fn: 68.0000\n",
            "Epoch 15/50\n",
            "7/7 - 0s - loss: 0.3875 - auc: 0.9688 - pr: 0.9792 - precision: 1.0000 - recall: 0.8086 - tp: 283.0000 - fp: 0.0000e+00 - tn: 350.0000 - fn: 67.0000\n",
            "Epoch 16/50\n",
            "7/7 - 0s - loss: 0.3886 - auc: 0.9604 - pr: 0.9728 - precision: 0.9964 - recall: 0.7919 - tp: 274.0000 - fp: 1.0000 - tn: 353.0000 - fn: 72.0000\n",
            "Epoch 17/50\n",
            "7/7 - 0s - loss: 0.3709 - auc: 0.9619 - pr: 0.9760 - precision: 0.9966 - recall: 0.8385 - tp: 296.0000 - fp: 1.0000 - tn: 346.0000 - fn: 57.0000\n",
            "Epoch 18/50\n",
            "7/7 - 0s - loss: 0.3566 - auc: 0.9829 - pr: 0.9879 - precision: 1.0000 - recall: 0.8423 - tp: 299.0000 - fp: 0.0000e+00 - tn: 345.0000 - fn: 56.0000\n",
            "Epoch 19/50\n",
            "7/7 - 0s - loss: 0.3660 - auc: 0.9664 - pr: 0.9781 - precision: 1.0000 - recall: 0.8159 - tp: 288.0000 - fp: 0.0000e+00 - tn: 347.0000 - fn: 65.0000\n",
            "Epoch 20/50\n",
            "7/7 - 0s - loss: 0.3602 - auc: 0.9654 - pr: 0.9777 - precision: 1.0000 - recall: 0.8063 - tp: 283.0000 - fp: 0.0000e+00 - tn: 349.0000 - fn: 68.0000\n",
            "Epoch 21/50\n",
            "7/7 - 0s - loss: 0.3752 - auc: 0.9586 - pr: 0.9679 - precision: 0.9924 - recall: 0.7814 - tp: 261.0000 - fp: 2.0000 - tn: 364.0000 - fn: 73.0000\n",
            "Epoch 22/50\n",
            "7/7 - 0s - loss: 0.3739 - auc: 0.9584 - pr: 0.9728 - precision: 0.9900 - recall: 0.7968 - tp: 298.0000 - fp: 3.0000 - tn: 323.0000 - fn: 76.0000\n",
            "Epoch 23/50\n",
            "7/7 - 0s - loss: 0.3569 - auc: 0.9636 - pr: 0.9744 - precision: 0.9930 - recall: 0.8034 - tp: 282.0000 - fp: 2.0000 - tn: 347.0000 - fn: 69.0000\n",
            "Epoch 24/50\n",
            "7/7 - 0s - loss: 0.3521 - auc: 0.9669 - pr: 0.9739 - precision: 0.9888 - recall: 0.7881 - tp: 264.0000 - fp: 3.0000 - tn: 362.0000 - fn: 71.0000\n",
            "Epoch 25/50\n",
            "7/7 - 0s - loss: 0.3357 - auc: 0.9722 - pr: 0.9801 - precision: 1.0000 - recall: 0.8216 - tp: 281.0000 - fp: 0.0000e+00 - tn: 358.0000 - fn: 61.0000\n",
            "Epoch 26/50\n",
            "7/7 - 0s - loss: 0.3304 - auc: 0.9727 - pr: 0.9805 - precision: 1.0000 - recall: 0.8487 - tp: 303.0000 - fp: 0.0000e+00 - tn: 343.0000 - fn: 54.0000\n",
            "Epoch 27/50\n",
            "7/7 - 0s - loss: 0.3250 - auc: 0.9675 - pr: 0.9788 - precision: 1.0000 - recall: 0.8506 - tp: 296.0000 - fp: 0.0000e+00 - tn: 352.0000 - fn: 52.0000\n",
            "Epoch 28/50\n",
            "7/7 - 0s - loss: 0.3391 - auc: 0.9563 - pr: 0.9701 - precision: 0.9894 - recall: 0.8145 - tp: 281.0000 - fp: 3.0000 - tn: 352.0000 - fn: 64.0000\n",
            "Epoch 29/50\n",
            "7/7 - 0s - loss: 0.3084 - auc: 0.9767 - pr: 0.9845 - precision: 1.0000 - recall: 0.8580 - tp: 302.0000 - fp: 0.0000e+00 - tn: 348.0000 - fn: 50.0000\n",
            "Epoch 30/50\n",
            "7/7 - 0s - loss: 0.3043 - auc: 0.9754 - pr: 0.9836 - precision: 1.0000 - recall: 0.8652 - tp: 308.0000 - fp: 0.0000e+00 - tn: 344.0000 - fn: 48.0000\n",
            "Epoch 31/50\n",
            "7/7 - 0s - loss: 0.3105 - auc: 0.9648 - pr: 0.9770 - precision: 0.9933 - recall: 0.8477 - tp: 295.0000 - fp: 2.0000 - tn: 350.0000 - fn: 53.0000\n",
            "Epoch 32/50\n",
            "7/7 - 0s - loss: 0.3299 - auc: 0.9670 - pr: 0.9758 - precision: 0.9929 - recall: 0.7955 - tp: 280.0000 - fp: 2.0000 - tn: 346.0000 - fn: 72.0000\n",
            "Epoch 33/50\n",
            "7/7 - 0s - loss: 0.3502 - auc: 0.9418 - pr: 0.9595 - precision: 0.9892 - recall: 0.7863 - tp: 276.0000 - fp: 3.0000 - tn: 346.0000 - fn: 75.0000\n",
            "Epoch 34/50\n",
            "7/7 - 0s - loss: 0.2908 - auc: 0.9810 - pr: 0.9862 - precision: 0.9814 - recall: 0.8729 - tp: 316.0000 - fp: 6.0000 - tn: 332.0000 - fn: 46.0000\n",
            "Epoch 35/50\n",
            "7/7 - 0s - loss: 0.3352 - auc: 0.9547 - pr: 0.9662 - precision: 0.9821 - recall: 0.7835 - tp: 275.0000 - fp: 5.0000 - tn: 344.0000 - fn: 76.0000\n",
            "Epoch 36/50\n",
            "7/7 - 0s - loss: 0.2839 - auc: 0.9765 - pr: 0.9814 - precision: 0.9892 - recall: 0.8440 - tp: 276.0000 - fp: 3.0000 - tn: 370.0000 - fn: 51.0000\n",
            "Epoch 37/50\n",
            "7/7 - 0s - loss: 0.2981 - auc: 0.9703 - pr: 0.9799 - precision: 0.9937 - recall: 0.8599 - tp: 313.0000 - fp: 2.0000 - tn: 334.0000 - fn: 51.0000\n",
            "Epoch 38/50\n",
            "7/7 - 0s - loss: 0.2885 - auc: 0.9688 - pr: 0.9788 - precision: 0.9899 - recall: 0.8477 - tp: 295.0000 - fp: 3.0000 - tn: 349.0000 - fn: 53.0000\n",
            "Epoch 39/50\n",
            "7/7 - 0s - loss: 0.2998 - auc: 0.9585 - pr: 0.9703 - precision: 0.9892 - recall: 0.8190 - tp: 276.0000 - fp: 3.0000 - tn: 360.0000 - fn: 61.0000\n",
            "Epoch 40/50\n",
            "7/7 - 0s - loss: 0.2896 - auc: 0.9603 - pr: 0.9746 - precision: 0.9870 - recall: 0.8588 - tp: 304.0000 - fp: 4.0000 - tn: 342.0000 - fn: 50.0000\n",
            "Epoch 41/50\n",
            "7/7 - 0s - loss: 0.2527 - auc: 0.9814 - pr: 0.9883 - precision: 1.0000 - recall: 0.8904 - tp: 325.0000 - fp: 0.0000e+00 - tn: 335.0000 - fn: 40.0000\n",
            "Epoch 42/50\n",
            "7/7 - 0s - loss: 0.2706 - auc: 0.9721 - pr: 0.9808 - precision: 0.9903 - recall: 0.8722 - tp: 307.0000 - fp: 3.0000 - tn: 345.0000 - fn: 45.0000\n",
            "Epoch 43/50\n",
            "7/7 - 0s - loss: 0.2909 - auc: 0.9604 - pr: 0.9725 - precision: 0.9965 - recall: 0.8192 - tp: 281.0000 - fp: 1.0000 - tn: 356.0000 - fn: 62.0000\n",
            "Epoch 44/50\n",
            "7/7 - 0s - loss: 0.3054 - auc: 0.9576 - pr: 0.9686 - precision: 0.9755 - recall: 0.8064 - tp: 279.0000 - fp: 7.0000 - tn: 347.0000 - fn: 67.0000\n",
            "Epoch 45/50\n",
            "7/7 - 0s - loss: 0.2896 - auc: 0.9616 - pr: 0.9742 - precision: 0.9687 - recall: 0.8443 - tp: 309.0000 - fp: 10.0000 - tn: 324.0000 - fn: 57.0000\n",
            "Epoch 46/50\n",
            "7/7 - 0s - loss: 0.2988 - auc: 0.9581 - pr: 0.9706 - precision: 0.9742 - recall: 0.8436 - tp: 302.0000 - fp: 8.0000 - tn: 334.0000 - fn: 56.0000\n",
            "Epoch 47/50\n",
            "7/7 - 0s - loss: 0.2580 - auc: 0.9731 - pr: 0.9779 - precision: 0.9822 - recall: 0.8519 - tp: 276.0000 - fp: 5.0000 - tn: 371.0000 - fn: 48.0000\n",
            "Epoch 48/50\n",
            "7/7 - 0s - loss: 0.2728 - auc: 0.9697 - pr: 0.9780 - precision: 0.9899 - recall: 0.8444 - tp: 293.0000 - fp: 3.0000 - tn: 350.0000 - fn: 54.0000\n",
            "Epoch 49/50\n",
            "7/7 - 0s - loss: 0.2550 - auc: 0.9708 - pr: 0.9801 - precision: 0.9843 - recall: 0.8719 - tp: 313.0000 - fp: 5.0000 - tn: 336.0000 - fn: 46.0000\n",
            "Epoch 50/50\n",
            "7/7 - 0s - loss: 0.2586 - auc: 0.9650 - pr: 0.9764 - precision: 0.9769 - recall: 0.8680 - tp: 296.0000 - fp: 7.0000 - tn: 352.0000 - fn: 45.0000\n",
            "Model #0 fit finished with best pr: 0.9882808923721313 in epoch: 41\n",
            "\n",
            "Training of the model with best HP from Hyperband search\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC4C63700>\n",
            "(80000, 2)\n",
            "(80000,)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7/7 - 2s - loss: 0.4065 - auc: 0.9635 - pr: 0.9770 - precision: 1.0000 - recall: 0.7624 - tp: 276.0000 - fp: 0.0000e+00 - tn: 338.0000 - fn: 86.0000\n",
            "Epoch 2/50\n",
            "7/7 - 0s - loss: 0.3754 - auc: 0.9823 - pr: 0.9869 - precision: 1.0000 - recall: 0.7778 - tp: 273.0000 - fp: 0.0000e+00 - tn: 349.0000 - fn: 78.0000\n",
            "Epoch 3/50\n",
            "7/7 - 0s - loss: 0.3725 - auc: 0.9609 - pr: 0.9760 - precision: 1.0000 - recall: 0.7695 - tp: 267.0000 - fp: 0.0000e+00 - tn: 353.0000 - fn: 80.0000\n",
            "Epoch 4/50\n",
            "7/7 - 0s - loss: 0.3551 - auc: 0.9717 - pr: 0.9818 - precision: 1.0000 - recall: 0.7737 - tp: 277.0000 - fp: 0.0000e+00 - tn: 342.0000 - fn: 81.0000\n",
            "Epoch 5/50\n",
            "7/7 - 0s - loss: 0.3677 - auc: 0.9554 - pr: 0.9662 - precision: 1.0000 - recall: 0.7305 - tp: 244.0000 - fp: 0.0000e+00 - tn: 366.0000 - fn: 90.0000\n",
            "Epoch 6/50\n",
            "7/7 - 0s - loss: 0.3608 - auc: 0.9553 - pr: 0.9701 - precision: 0.9928 - recall: 0.7631 - tp: 277.0000 - fp: 2.0000 - tn: 335.0000 - fn: 86.0000\n",
            "Epoch 7/50\n",
            "7/7 - 0s - loss: 0.3396 - auc: 0.9634 - pr: 0.9757 - precision: 1.0000 - recall: 0.7889 - tp: 284.0000 - fp: 0.0000e+00 - tn: 340.0000 - fn: 76.0000\n",
            "Epoch 8/50\n",
            "7/7 - 0s - loss: 0.3272 - auc: 0.9671 - pr: 0.9746 - precision: 0.9927 - recall: 0.7930 - tp: 272.0000 - fp: 2.0000 - tn: 355.0000 - fn: 71.0000\n",
            "Epoch 9/50\n",
            "7/7 - 0s - loss: 0.3183 - auc: 0.9696 - pr: 0.9789 - precision: 1.0000 - recall: 0.7965 - tp: 274.0000 - fp: 0.0000e+00 - tn: 356.0000 - fn: 70.0000\n",
            "Epoch 10/50\n",
            "7/7 - 0s - loss: 0.3043 - auc: 0.9688 - pr: 0.9779 - precision: 1.0000 - recall: 0.8367 - tp: 292.0000 - fp: 0.0000e+00 - tn: 351.0000 - fn: 57.0000\n",
            "Epoch 11/50\n",
            "7/7 - 0s - loss: 0.2981 - auc: 0.9678 - pr: 0.9797 - precision: 1.0000 - recall: 0.8451 - tp: 300.0000 - fp: 0.0000e+00 - tn: 345.0000 - fn: 55.0000\n",
            "Epoch 12/50\n",
            "7/7 - 0s - loss: 0.3102 - auc: 0.9620 - pr: 0.9720 - precision: 0.9962 - recall: 0.7958 - tp: 265.0000 - fp: 1.0000 - tn: 366.0000 - fn: 68.0000\n",
            "Epoch 13/50\n",
            "7/7 - 0s - loss: 0.2751 - auc: 0.9748 - pr: 0.9832 - precision: 0.9968 - recall: 0.8552 - tp: 307.0000 - fp: 1.0000 - tn: 340.0000 - fn: 52.0000\n",
            "Epoch 14/50\n",
            "7/7 - 0s - loss: 0.2714 - auc: 0.9736 - pr: 0.9837 - precision: 1.0000 - recall: 0.8588 - tp: 304.0000 - fp: 0.0000e+00 - tn: 346.0000 - fn: 50.0000\n",
            "Epoch 15/50\n",
            "7/7 - 0s - loss: 0.2836 - auc: 0.9642 - pr: 0.9761 - precision: 0.9966 - recall: 0.8405 - tp: 295.0000 - fp: 1.0000 - tn: 348.0000 - fn: 56.0000\n",
            "Epoch 16/50\n",
            "7/7 - 0s - loss: 0.2872 - auc: 0.9663 - pr: 0.9760 - precision: 0.9929 - recall: 0.8046 - tp: 280.0000 - fp: 2.0000 - tn: 350.0000 - fn: 68.0000\n",
            "Epoch 17/50\n",
            "7/7 - 0s - loss: 0.3196 - auc: 0.9420 - pr: 0.9601 - precision: 0.9964 - recall: 0.7898 - tp: 278.0000 - fp: 1.0000 - tn: 347.0000 - fn: 74.0000\n",
            "Epoch 18/50\n",
            "7/7 - 0s - loss: 0.2611 - auc: 0.9777 - pr: 0.9838 - precision: 0.9781 - recall: 0.8667 - tp: 312.0000 - fp: 7.0000 - tn: 333.0000 - fn: 48.0000\n",
            "Epoch 19/50\n",
            "7/7 - 0s - loss: 0.3148 - auc: 0.9463 - pr: 0.9631 - precision: 0.9759 - recall: 0.7889 - tp: 284.0000 - fp: 7.0000 - tn: 333.0000 - fn: 76.0000\n",
            "Epoch 20/50\n",
            "7/7 - 0s - loss: 0.2525 - auc: 0.9712 - pr: 0.9782 - precision: 0.9891 - recall: 0.8390 - tp: 271.0000 - fp: 3.0000 - tn: 374.0000 - fn: 52.0000\n",
            "Epoch 21/50\n",
            "7/7 - 0s - loss: 0.2598 - auc: 0.9713 - pr: 0.9803 - precision: 0.9903 - recall: 0.8672 - tp: 307.0000 - fp: 3.0000 - tn: 343.0000 - fn: 47.0000\n",
            "Epoch 22/50\n",
            "7/7 - 0s - loss: 0.2559 - auc: 0.9717 - pr: 0.9805 - precision: 0.9933 - recall: 0.8514 - tp: 298.0000 - fp: 2.0000 - tn: 348.0000 - fn: 52.0000\n",
            "Epoch 23/50\n",
            "7/7 - 0s - loss: 0.2734 - auc: 0.9607 - pr: 0.9730 - precision: 0.9861 - recall: 0.8179 - tp: 283.0000 - fp: 4.0000 - tn: 350.0000 - fn: 63.0000\n",
            "Epoch 24/50\n",
            "7/7 - 0s - loss: 0.2470 - auc: 0.9648 - pr: 0.9767 - precision: 0.9904 - recall: 0.8782 - tp: 310.0000 - fp: 3.0000 - tn: 344.0000 - fn: 43.0000\n",
            "Epoch 25/50\n",
            "7/7 - 0s - loss: 0.2299 - auc: 0.9810 - pr: 0.9868 - precision: 0.9968 - recall: 0.8873 - tp: 315.0000 - fp: 1.0000 - tn: 344.0000 - fn: 40.0000\n",
            "Epoch 26/50\n",
            "7/7 - 0s - loss: 0.2564 - auc: 0.9620 - pr: 0.9760 - precision: 0.9903 - recall: 0.8697 - tp: 307.0000 - fp: 3.0000 - tn: 344.0000 - fn: 46.0000\n",
            "Epoch 27/50\n",
            "7/7 - 0s - loss: 0.2488 - auc: 0.9666 - pr: 0.9773 - precision: 0.9933 - recall: 0.8462 - tp: 297.0000 - fp: 2.0000 - tn: 347.0000 - fn: 54.0000\n",
            "Epoch 28/50\n",
            "7/7 - 0s - loss: 0.2778 - auc: 0.9532 - pr: 0.9652 - precision: 0.9783 - recall: 0.8084 - tp: 270.0000 - fp: 6.0000 - tn: 360.0000 - fn: 64.0000\n",
            "Epoch 29/50\n",
            "7/7 - 0s - loss: 0.2759 - auc: 0.9555 - pr: 0.9708 - precision: 0.9688 - recall: 0.8289 - tp: 310.0000 - fp: 10.0000 - tn: 316.0000 - fn: 64.0000\n",
            "Epoch 30/50\n",
            "7/7 - 0s - loss: 0.2597 - auc: 0.9594 - pr: 0.9720 - precision: 0.9707 - recall: 0.8490 - tp: 298.0000 - fp: 9.0000 - tn: 340.0000 - fn: 53.0000\n",
            "Epoch 31/50\n",
            "7/7 - 0s - loss: 0.2591 - auc: 0.9586 - pr: 0.9693 - precision: 0.9792 - recall: 0.8418 - tp: 282.0000 - fp: 6.0000 - tn: 359.0000 - fn: 53.0000\n",
            "Epoch 32/50\n",
            "7/7 - 0s - loss: 0.2353 - auc: 0.9724 - pr: 0.9799 - precision: 0.9932 - recall: 0.8596 - tp: 294.0000 - fp: 2.0000 - tn: 356.0000 - fn: 48.0000\n",
            "Epoch 33/50\n",
            "7/7 - 0s - loss: 0.2316 - auc: 0.9716 - pr: 0.9800 - precision: 0.9841 - recall: 0.8683 - tp: 310.0000 - fp: 5.0000 - tn: 338.0000 - fn: 47.0000\n",
            "Epoch 34/50\n",
            "7/7 - 0s - loss: 0.2353 - auc: 0.9686 - pr: 0.9793 - precision: 0.9777 - recall: 0.8822 - tp: 307.0000 - fp: 7.0000 - tn: 345.0000 - fn: 41.0000\n",
            "Epoch 35/50\n",
            "7/7 - 0s - loss: 0.2555 - auc: 0.9585 - pr: 0.9710 - precision: 0.9733 - recall: 0.8464 - tp: 292.0000 - fp: 8.0000 - tn: 347.0000 - fn: 53.0000\n",
            "Epoch 36/50\n",
            "7/7 - 0s - loss: 0.2112 - auc: 0.9777 - pr: 0.9845 - precision: 0.9936 - recall: 0.8864 - tp: 312.0000 - fp: 2.0000 - tn: 346.0000 - fn: 40.0000\n",
            "Epoch 37/50\n",
            "7/7 - 0s - loss: 0.2224 - auc: 0.9710 - pr: 0.9817 - precision: 0.9907 - recall: 0.8933 - tp: 318.0000 - fp: 3.0000 - tn: 341.0000 - fn: 38.0000\n",
            "Epoch 38/50\n",
            "7/7 - 0s - loss: 0.2312 - auc: 0.9648 - pr: 0.9765 - precision: 0.9902 - recall: 0.8678 - tp: 302.0000 - fp: 3.0000 - tn: 349.0000 - fn: 46.0000\n",
            "Epoch 39/50\n",
            "7/7 - 0s - loss: 0.2559 - auc: 0.9636 - pr: 0.9736 - precision: 0.9796 - recall: 0.8182 - tp: 288.0000 - fp: 6.0000 - tn: 342.0000 - fn: 64.0000\n",
            "Epoch 40/50\n",
            "7/7 - 0s - loss: 0.2928 - auc: 0.9364 - pr: 0.9564 - precision: 0.9726 - recall: 0.8091 - tp: 284.0000 - fp: 8.0000 - tn: 341.0000 - fn: 67.0000\n",
            "Epoch 41/50\n",
            "7/7 - 0s - loss: 0.2101 - auc: 0.9786 - pr: 0.9851 - precision: 0.9699 - recall: 0.8895 - tp: 322.0000 - fp: 10.0000 - tn: 328.0000 - fn: 40.0000\n",
            "Epoch 42/50\n",
            "7/7 - 0s - loss: 0.2786 - auc: 0.9482 - pr: 0.9626 - precision: 0.9764 - recall: 0.8234 - tp: 289.0000 - fp: 7.0000 - tn: 342.0000 - fn: 62.0000\n",
            "Epoch 43/50\n",
            "7/7 - 0s - loss: 0.2131 - auc: 0.9725 - pr: 0.9795 - precision: 0.9763 - recall: 0.8807 - tp: 288.0000 - fp: 7.0000 - tn: 366.0000 - fn: 39.0000\n",
            "Epoch 44/50\n",
            "7/7 - 0s - loss: 0.2331 - auc: 0.9672 - pr: 0.9785 - precision: 0.9846 - recall: 0.8764 - tp: 319.0000 - fp: 5.0000 - tn: 331.0000 - fn: 45.0000\n",
            "Epoch 45/50\n",
            "7/7 - 0s - loss: 0.2203 - auc: 0.9715 - pr: 0.9802 - precision: 0.9743 - recall: 0.8707 - tp: 303.0000 - fp: 8.0000 - tn: 344.0000 - fn: 45.0000\n",
            "Epoch 46/50\n",
            "7/7 - 0s - loss: 0.2427 - auc: 0.9604 - pr: 0.9713 - precision: 0.9826 - recall: 0.8368 - tp: 282.0000 - fp: 5.0000 - tn: 358.0000 - fn: 55.0000\n",
            "Epoch 47/50\n",
            "7/7 - 0s - loss: 0.2289 - auc: 0.9627 - pr: 0.9751 - precision: 0.9780 - recall: 0.8785 - tp: 311.0000 - fp: 7.0000 - tn: 339.0000 - fn: 43.0000\n",
            "Epoch 48/50\n",
            "7/7 - 0s - loss: 0.1921 - auc: 0.9777 - pr: 0.9866 - precision: 0.9940 - recall: 0.9041 - tp: 330.0000 - fp: 2.0000 - tn: 333.0000 - fn: 35.0000\n",
            "Epoch 49/50\n",
            "7/7 - 0s - loss: 0.2157 - auc: 0.9694 - pr: 0.9797 - precision: 0.9811 - recall: 0.8835 - tp: 311.0000 - fp: 6.0000 - tn: 342.0000 - fn: 41.0000\n",
            "Epoch 50/50\n",
            "7/7 - 0s - loss: 0.2409 - auc: 0.9615 - pr: 0.9724 - precision: 0.9965 - recall: 0.8367 - tp: 287.0000 - fp: 1.0000 - tn: 356.0000 - fn: 56.0000\n",
            "Model #1 fit finished with best pr: 0.986931562423706 in epoch: 2\n",
            "\n",
            "Training of the model with best HP from BayesianOptimization search\n",
            "<tensorflow.python.keras.engine.sequential.Sequential object at 0x0000024BC21AFE80>\n",
            "(80000, 2)\n",
            "(80000,)\n",
            "Epoch 1/50\n",
            "7/7 - 2s - loss: 0.2387 - auc: 0.9528 - pr: 0.9674 - precision: 0.9590 - recall: 0.8612 - tp: 304.0000 - fp: 13.0000 - tn: 334.0000 - fn: 49.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "7/7 - 0s - loss: 0.1903 - auc: 0.9755 - pr: 0.9820 - precision: 0.9527 - recall: 0.9045 - tp: 322.0000 - fp: 16.0000 - tn: 328.0000 - fn: 34.0000\n",
            "Epoch 3/50\n",
            "7/7 - 0s - loss: 0.2617 - auc: 0.9502 - pr: 0.9659 - precision: 0.9530 - recall: 0.8468 - tp: 304.0000 - fp: 15.0000 - tn: 326.0000 - fn: 55.0000\n",
            "Epoch 4/50\n",
            "7/7 - 0s - loss: 0.1757 - auc: 0.9724 - pr: 0.9787 - precision: 0.9582 - recall: 0.9283 - tp: 298.0000 - fp: 13.0000 - tn: 366.0000 - fn: 23.0000\n",
            "Epoch 5/50\n",
            "7/7 - 0s - loss: 0.2008 - auc: 0.9669 - pr: 0.9772 - precision: 0.9632 - recall: 0.8920 - tp: 314.0000 - fp: 12.0000 - tn: 336.0000 - fn: 38.0000\n",
            "Epoch 6/50\n",
            "7/7 - 0s - loss: 0.1858 - auc: 0.9654 - pr: 0.9776 - precision: 0.9669 - recall: 0.9042 - tp: 321.0000 - fp: 11.0000 - tn: 334.0000 - fn: 34.0000\n",
            "Epoch 7/50\n",
            "7/7 - 0s - loss: 0.1879 - auc: 0.9639 - pr: 0.9759 - precision: 0.9772 - recall: 0.8876 - tp: 300.0000 - fp: 7.0000 - tn: 355.0000 - fn: 38.0000\n",
            "Epoch 8/50\n",
            "7/7 - 0s - loss: 0.1989 - auc: 0.9615 - pr: 0.9761 - precision: 0.9672 - recall: 0.8950 - tp: 324.0000 - fp: 11.0000 - tn: 327.0000 - fn: 38.0000\n",
            "Epoch 9/50\n",
            "7/7 - 0s - loss: 0.1420 - auc: 0.9829 - pr: 0.9872 - precision: 0.9757 - recall: 0.9145 - tp: 321.0000 - fp: 8.0000 - tn: 341.0000 - fn: 30.0000\n",
            "Epoch 10/50\n",
            "7/7 - 0s - loss: 0.1735 - auc: 0.9639 - pr: 0.9774 - precision: 0.9726 - recall: 0.9193 - tp: 319.0000 - fp: 9.0000 - tn: 344.0000 - fn: 28.0000\n",
            "Epoch 11/50\n",
            "7/7 - 0s - loss: 0.1666 - auc: 0.9712 - pr: 0.9817 - precision: 0.9702 - recall: 0.9106 - tp: 326.0000 - fp: 10.0000 - tn: 332.0000 - fn: 32.0000\n",
            "Epoch 12/50\n",
            "7/7 - 0s - loss: 0.2338 - auc: 0.9583 - pr: 0.9681 - precision: 0.9565 - recall: 0.8563 - tp: 286.0000 - fp: 13.0000 - tn: 353.0000 - fn: 48.0000\n",
            "Epoch 13/50\n",
            "7/7 - 0s - loss: 0.2342 - auc: 0.9517 - pr: 0.9687 - precision: 0.9716 - recall: 0.8485 - tp: 308.0000 - fp: 9.0000 - tn: 328.0000 - fn: 55.0000\n",
            "Epoch 14/50\n",
            "7/7 - 0s - loss: 0.2254 - auc: 0.9574 - pr: 0.9726 - precision: 0.9606 - recall: 0.8806 - tp: 317.0000 - fp: 13.0000 - tn: 327.0000 - fn: 43.0000\n",
            "Epoch 15/50\n",
            "7/7 - 0s - loss: 0.2060 - auc: 0.9663 - pr: 0.9723 - precision: 0.9288 - recall: 0.9125 - tp: 313.0000 - fp: 24.0000 - tn: 333.0000 - fn: 30.0000\n",
            "Epoch 16/50\n",
            "7/7 - 0s - loss: 0.1824 - auc: 0.9689 - pr: 0.9791 - precision: 1.0000 - recall: 0.8808 - tp: 303.0000 - fp: 0.0000e+00 - tn: 356.0000 - fn: 41.0000\n",
            "Epoch 17/50\n",
            "7/7 - 0s - loss: 0.1898 - auc: 0.9685 - pr: 0.9777 - precision: 0.9412 - recall: 0.9169 - tp: 320.0000 - fp: 20.0000 - tn: 331.0000 - fn: 29.0000\n",
            "Epoch 18/50\n",
            "7/7 - 0s - loss: 0.1788 - auc: 0.9646 - pr: 0.9783 - precision: 0.9729 - recall: 0.9099 - tp: 323.0000 - fp: 9.0000 - tn: 336.0000 - fn: 32.0000\n",
            "Epoch 19/50\n",
            "7/7 - 0s - loss: 0.2064 - auc: 0.9616 - pr: 0.9721 - precision: 0.9578 - recall: 0.8859 - tp: 295.0000 - fp: 13.0000 - tn: 354.0000 - fn: 38.0000\n",
            "Epoch 20/50\n",
            "7/7 - 0s - loss: 0.1638 - auc: 0.9742 - pr: 0.9833 - precision: 0.9731 - recall: 0.9081 - tp: 326.0000 - fp: 9.0000 - tn: 332.0000 - fn: 33.0000\n",
            "Epoch 21/50\n",
            "7/7 - 0s - loss: 0.1434 - auc: 0.9755 - pr: 0.9849 - precision: 0.9820 - recall: 0.9266 - tp: 328.0000 - fp: 6.0000 - tn: 340.0000 - fn: 26.0000\n",
            "Epoch 22/50\n",
            "7/7 - 0s - loss: 0.1803 - auc: 0.9635 - pr: 0.9769 - precision: 0.9610 - recall: 0.9117 - tp: 320.0000 - fp: 13.0000 - tn: 336.0000 - fn: 31.0000\n",
            "Epoch 23/50\n",
            "7/7 - 0s - loss: 0.2065 - auc: 0.9665 - pr: 0.9741 - precision: 0.9569 - recall: 0.8937 - tp: 311.0000 - fp: 14.0000 - tn: 338.0000 - fn: 37.0000\n",
            "Epoch 24/50\n",
            "7/7 - 0s - loss: 0.2471 - auc: 0.9488 - pr: 0.9642 - precision: 0.9799 - recall: 0.8295 - tp: 292.0000 - fp: 6.0000 - tn: 342.0000 - fn: 60.0000\n",
            "Epoch 25/50\n",
            "7/7 - 0s - loss: 0.1773 - auc: 0.9791 - pr: 0.9858 - precision: 0.9678 - recall: 0.9194 - tp: 331.0000 - fp: 11.0000 - tn: 329.0000 - fn: 29.0000\n",
            "Epoch 26/50\n",
            "7/7 - 0s - loss: 0.2657 - auc: 0.9500 - pr: 0.9628 - precision: 0.9303 - recall: 0.8528 - tp: 307.0000 - fp: 23.0000 - tn: 317.0000 - fn: 53.0000\n",
            "Epoch 27/50\n",
            "7/7 - 0s - loss: 0.1686 - auc: 0.9701 - pr: 0.9776 - precision: 0.9768 - recall: 0.9133 - tp: 295.0000 - fp: 7.0000 - tn: 370.0000 - fn: 28.0000\n",
            "Epoch 28/50\n",
            "7/7 - 0s - loss: 0.1868 - auc: 0.9702 - pr: 0.9794 - precision: 0.9552 - recall: 0.9040 - tp: 320.0000 - fp: 15.0000 - tn: 331.0000 - fn: 34.0000\n",
            "Epoch 29/50\n",
            "7/7 - 0s - loss: 0.1739 - auc: 0.9701 - pr: 0.9799 - precision: 0.9697 - recall: 0.9143 - tp: 320.0000 - fp: 10.0000 - tn: 340.0000 - fn: 30.0000\n",
            "Epoch 30/50\n",
            "7/7 - 0s - loss: 0.2074 - auc: 0.9618 - pr: 0.9745 - precision: 0.9710 - recall: 0.8699 - tp: 301.0000 - fp: 9.0000 - tn: 345.0000 - fn: 45.0000\n",
            "Epoch 31/50\n",
            "7/7 - 0s - loss: 0.1848 - auc: 0.9633 - pr: 0.9769 - precision: 0.9697 - recall: 0.9065 - tp: 320.0000 - fp: 10.0000 - tn: 337.0000 - fn: 33.0000\n",
            "Epoch 32/50\n",
            "7/7 - 0s - loss: 0.1402 - auc: 0.9823 - pr: 0.9877 - precision: 0.9761 - recall: 0.9211 - tp: 327.0000 - fp: 8.0000 - tn: 337.0000 - fn: 28.0000\n",
            "Epoch 33/50\n",
            "7/7 - 0s - loss: 0.1785 - auc: 0.9636 - pr: 0.9778 - precision: 0.9614 - recall: 0.9178 - tp: 324.0000 - fp: 13.0000 - tn: 334.0000 - fn: 29.0000\n",
            "Epoch 34/50\n",
            "7/7 - 0s - loss: 0.1782 - auc: 0.9668 - pr: 0.9785 - precision: 0.9723 - recall: 0.9003 - tp: 316.0000 - fp: 9.0000 - tn: 340.0000 - fn: 35.0000\n",
            "Epoch 35/50\n",
            "7/7 - 0s - loss: 0.2336 - auc: 0.9542 - pr: 0.9637 - precision: 0.9635 - recall: 0.8683 - tp: 290.0000 - fp: 11.0000 - tn: 355.0000 - fn: 44.0000\n",
            "Epoch 36/50\n",
            "7/7 - 0s - loss: 0.2262 - auc: 0.9549 - pr: 0.9725 - precision: 0.9700 - recall: 0.8636 - tp: 323.0000 - fp: 10.0000 - tn: 316.0000 - fn: 51.0000\n",
            "Epoch 37/50\n",
            "7/7 - 0s - loss: 0.2205 - auc: 0.9571 - pr: 0.9713 - precision: 0.9599 - recall: 0.8860 - tp: 311.0000 - fp: 13.0000 - tn: 336.0000 - fn: 40.0000\n",
            "Epoch 38/50\n",
            "7/7 - 0s - loss: 0.2006 - auc: 0.9663 - pr: 0.9746 - precision: 0.9329 - recall: 0.9134 - tp: 306.0000 - fp: 22.0000 - tn: 343.0000 - fn: 29.0000\n",
            "Epoch 39/50\n",
            "7/7 - 0s - loss: 0.1795 - auc: 0.9707 - pr: 0.9801 - precision: 0.9838 - recall: 0.8860 - tp: 303.0000 - fp: 5.0000 - tn: 353.0000 - fn: 39.0000\n",
            "Epoch 40/50\n",
            "7/7 - 0s - loss: 0.1814 - auc: 0.9721 - pr: 0.9805 - precision: 0.9398 - recall: 0.9188 - tp: 328.0000 - fp: 21.0000 - tn: 322.0000 - fn: 29.0000\n",
            "Epoch 41/50\n",
            "7/7 - 0s - loss: 0.1787 - auc: 0.9676 - pr: 0.9788 - precision: 0.9783 - recall: 0.9052 - tp: 315.0000 - fp: 7.0000 - tn: 345.0000 - fn: 33.0000\n",
            "Epoch 42/50\n",
            "7/7 - 0s - loss: 0.2108 - auc: 0.9581 - pr: 0.9715 - precision: 0.9654 - recall: 0.8899 - tp: 307.0000 - fp: 11.0000 - tn: 344.0000 - fn: 38.0000\n",
            "Epoch 43/50\n",
            "7/7 - 0s - loss: 0.1535 - auc: 0.9774 - pr: 0.9846 - precision: 0.9757 - recall: 0.9119 - tp: 321.0000 - fp: 8.0000 - tn: 340.0000 - fn: 31.0000\n",
            "Epoch 44/50\n",
            "7/7 - 0s - loss: 0.1535 - auc: 0.9728 - pr: 0.9826 - precision: 0.9792 - recall: 0.9242 - tp: 329.0000 - fp: 7.0000 - tn: 337.0000 - fn: 27.0000\n",
            "Epoch 45/50\n",
            "7/7 - 0s - loss: 0.1672 - auc: 0.9666 - pr: 0.9789 - precision: 0.9667 - recall: 0.9167 - tp: 319.0000 - fp: 11.0000 - tn: 341.0000 - fn: 29.0000\n",
            "Epoch 46/50\n",
            "7/7 - 0s - loss: 0.2199 - auc: 0.9663 - pr: 0.9737 - precision: 0.9571 - recall: 0.8864 - tp: 312.0000 - fp: 14.0000 - tn: 334.0000 - fn: 40.0000\n",
            "Epoch 47/50\n",
            "7/7 - 0s - loss: 0.2551 - auc: 0.9401 - pr: 0.9602 - precision: 0.9797 - recall: 0.8234 - tp: 289.0000 - fp: 6.0000 - tn: 343.0000 - fn: 62.0000\n",
            "Epoch 48/50\n",
            "7/7 - 0s - loss: 0.1754 - auc: 0.9792 - pr: 0.9861 - precision: 0.9625 - recall: 0.9227 - tp: 334.0000 - fp: 13.0000 - tn: 325.0000 - fn: 28.0000\n",
            "Epoch 49/50\n",
            "7/7 - 0s - loss: 0.2444 - auc: 0.9542 - pr: 0.9669 - precision: 0.9383 - recall: 0.8661 - tp: 304.0000 - fp: 20.0000 - tn: 329.0000 - fn: 47.0000\n",
            "Epoch 50/50\n",
            "7/7 - 0s - loss: 0.1583 - auc: 0.9767 - pr: 0.9817 - precision: 0.9709 - recall: 0.9174 - tp: 300.0000 - fp: 9.0000 - tn: 364.0000 - fn: 27.0000\n",
            "Model #2 fit finished with best pr: 0.9877028465270996 in epoch: 32\n",
            "\n",
            "Retraining of the model #0\n",
            "Epoch 1/41\n",
            "800/800 - 3s - loss: 0.0827 - auc: 0.9665 - pr: 0.8646 - precision: 0.8741 - recall: 0.7690 - tp: 3076.0000 - fp: 443.0000 - tn: 75557.0000 - fn: 924.0000\n",
            "Epoch 2/41\n",
            "800/800 - 2s - loss: 0.0410 - auc: 0.9884 - pr: 0.9401 - precision: 0.9763 - recall: 0.7925 - tp: 3170.0000 - fp: 77.0000 - tn: 75923.0000 - fn: 830.0000\n",
            "Epoch 3/41\n",
            "800/800 - 2s - loss: 0.0363 - auc: 0.9903 - pr: 0.9467 - precision: 0.9803 - recall: 0.8080 - tp: 3232.0000 - fp: 65.0000 - tn: 75935.0000 - fn: 768.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/41\n",
            "800/800 - 2s - loss: 0.0336 - auc: 0.9912 - pr: 0.9515 - precision: 0.9812 - recall: 0.8235 - tp: 3294.0000 - fp: 63.0000 - tn: 75937.0000 - fn: 706.0000\n",
            "Epoch 5/41\n",
            "800/800 - 2s - loss: 0.0316 - auc: 0.9917 - pr: 0.9550 - precision: 0.9829 - recall: 0.8325 - tp: 3330.0000 - fp: 58.0000 - tn: 75942.0000 - fn: 670.0000\n",
            "Epoch 6/41\n",
            "800/800 - 3s - loss: 0.0301 - auc: 0.9919 - pr: 0.9575 - precision: 0.9847 - recall: 0.8385 - tp: 3354.0000 - fp: 52.0000 - tn: 75948.0000 - fn: 646.0000\n",
            "Epoch 7/41\n",
            "800/800 - 2s - loss: 0.0289 - auc: 0.9921 - pr: 0.9596 - precision: 0.9846 - recall: 0.8453 - tp: 3381.0000 - fp: 53.0000 - tn: 75947.0000 - fn: 619.0000\n",
            "Epoch 8/41\n",
            "800/800 - 2s - loss: 0.0279 - auc: 0.9925 - pr: 0.9611 - precision: 0.9841 - recall: 0.8503 - tp: 3401.0000 - fp: 55.0000 - tn: 75945.0000 - fn: 599.0000\n",
            "Epoch 9/41\n",
            "800/800 - 2s - loss: 0.0272 - auc: 0.9921 - pr: 0.9619 - precision: 0.9833 - recall: 0.8555 - tp: 3422.0000 - fp: 58.0000 - tn: 75942.0000 - fn: 578.0000\n",
            "Epoch 10/41\n",
            "800/800 - 3s - loss: 0.0266 - auc: 0.9921 - pr: 0.9628 - precision: 0.9840 - recall: 0.8597 - tp: 3439.0000 - fp: 56.0000 - tn: 75944.0000 - fn: 561.0000\n",
            "Epoch 11/41\n",
            "800/800 - 2s - loss: 0.0261 - auc: 0.9923 - pr: 0.9635 - precision: 0.9815 - recall: 0.8637 - tp: 3455.0000 - fp: 65.0000 - tn: 75935.0000 - fn: 545.0000\n",
            "Epoch 12/41\n",
            "800/800 - 3s - loss: 0.0257 - auc: 0.9921 - pr: 0.9640 - precision: 0.9813 - recall: 0.8668 - tp: 3467.0000 - fp: 66.0000 - tn: 75934.0000 - fn: 533.0000\n",
            "Epoch 13/41\n",
            "800/800 - 2s - loss: 0.0254 - auc: 0.9922 - pr: 0.9643 - precision: 0.9792 - recall: 0.8702 - tp: 3481.0000 - fp: 74.0000 - tn: 75926.0000 - fn: 519.0000\n",
            "Epoch 14/41\n",
            "800/800 - 4s - loss: 0.0251 - auc: 0.9922 - pr: 0.9646 - precision: 0.9787 - recall: 0.8717 - tp: 3487.0000 - fp: 76.0000 - tn: 75924.0000 - fn: 513.0000\n",
            "Epoch 15/41\n",
            "800/800 - 3s - loss: 0.0249 - auc: 0.9921 - pr: 0.9649 - precision: 0.9771 - recall: 0.8740 - tp: 3496.0000 - fp: 82.0000 - tn: 75918.0000 - fn: 504.0000\n",
            "Epoch 16/41\n",
            "800/800 - 4s - loss: 0.0247 - auc: 0.9921 - pr: 0.9650 - precision: 0.9763 - recall: 0.8750 - tp: 3500.0000 - fp: 85.0000 - tn: 75915.0000 - fn: 500.0000\n",
            "Epoch 17/41\n",
            "800/800 - 3s - loss: 0.0245 - auc: 0.9921 - pr: 0.9652 - precision: 0.9763 - recall: 0.8755 - tp: 3502.0000 - fp: 85.0000 - tn: 75915.0000 - fn: 498.0000\n",
            "Epoch 18/41\n",
            "800/800 - 4s - loss: 0.0244 - auc: 0.9922 - pr: 0.9653 - precision: 0.9742 - recall: 0.8783 - tp: 3513.0000 - fp: 93.0000 - tn: 75907.0000 - fn: 487.0000\n",
            "Epoch 19/41\n",
            "800/800 - 3s - loss: 0.0243 - auc: 0.9918 - pr: 0.9653 - precision: 0.9743 - recall: 0.8798 - tp: 3519.0000 - fp: 93.0000 - tn: 75907.0000 - fn: 481.0000\n",
            "Epoch 20/41\n",
            "800/800 - 3s - loss: 0.0242 - auc: 0.9918 - pr: 0.9653 - precision: 0.9735 - recall: 0.8802 - tp: 3521.0000 - fp: 96.0000 - tn: 75904.0000 - fn: 479.0000\n",
            "Epoch 21/41\n",
            "800/800 - 3s - loss: 0.0241 - auc: 0.9921 - pr: 0.9656 - precision: 0.9727 - recall: 0.8827 - tp: 3531.0000 - fp: 99.0000 - tn: 75901.0000 - fn: 469.0000\n",
            "Epoch 22/41\n",
            "800/800 - 2s - loss: 0.0240 - auc: 0.9919 - pr: 0.9656 - precision: 0.9717 - recall: 0.8855 - tp: 3542.0000 - fp: 103.0000 - tn: 75897.0000 - fn: 458.0000\n",
            "Epoch 23/41\n",
            "800/800 - 2s - loss: 0.0240 - auc: 0.9918 - pr: 0.9656 - precision: 0.9715 - recall: 0.8855 - tp: 3542.0000 - fp: 104.0000 - tn: 75896.0000 - fn: 458.0000\n",
            "Epoch 24/41\n",
            "800/800 - 2s - loss: 0.0239 - auc: 0.9919 - pr: 0.9656 - precision: 0.9720 - recall: 0.8850 - tp: 3540.0000 - fp: 102.0000 - tn: 75898.0000 - fn: 460.0000\n",
            "Epoch 25/41\n",
            "800/800 - 3s - loss: 0.0239 - auc: 0.9918 - pr: 0.9656 - precision: 0.9720 - recall: 0.8867 - tp: 3547.0000 - fp: 102.0000 - tn: 75898.0000 - fn: 453.0000\n",
            "Epoch 26/41\n",
            "800/800 - 3s - loss: 0.0239 - auc: 0.9918 - pr: 0.9656 - precision: 0.9710 - recall: 0.8885 - tp: 3554.0000 - fp: 106.0000 - tn: 75894.0000 - fn: 446.0000\n",
            "Epoch 27/41\n",
            "800/800 - 3s - loss: 0.0238 - auc: 0.9917 - pr: 0.9656 - precision: 0.9700 - recall: 0.8880 - tp: 3552.0000 - fp: 110.0000 - tn: 75890.0000 - fn: 448.0000\n",
            "Epoch 28/41\n",
            "800/800 - 2s - loss: 0.0238 - auc: 0.9917 - pr: 0.9656 - precision: 0.9705 - recall: 0.8895 - tp: 3558.0000 - fp: 108.0000 - tn: 75892.0000 - fn: 442.0000\n",
            "Epoch 29/41\n",
            "800/800 - 2s - loss: 0.0238 - auc: 0.9917 - pr: 0.9657 - precision: 0.9698 - recall: 0.8898 - tp: 3559.0000 - fp: 111.0000 - tn: 75889.0000 - fn: 441.0000\n",
            "Epoch 30/41\n",
            "800/800 - 2s - loss: 0.0237 - auc: 0.9917 - pr: 0.9658 - precision: 0.9690 - recall: 0.8898 - tp: 3559.0000 - fp: 114.0000 - tn: 75886.0000 - fn: 441.0000\n",
            "Epoch 31/41\n",
            "800/800 - 2s - loss: 0.0237 - auc: 0.9918 - pr: 0.9658 - precision: 0.9695 - recall: 0.8890 - tp: 3556.0000 - fp: 112.0000 - tn: 75888.0000 - fn: 444.0000\n",
            "Epoch 32/41\n",
            "800/800 - 2s - loss: 0.0237 - auc: 0.9919 - pr: 0.9659 - precision: 0.9698 - recall: 0.8898 - tp: 3559.0000 - fp: 111.0000 - tn: 75889.0000 - fn: 441.0000\n",
            "Epoch 33/41\n",
            "800/800 - 2s - loss: 0.0236 - auc: 0.9920 - pr: 0.9659 - precision: 0.9687 - recall: 0.8910 - tp: 3564.0000 - fp: 115.0000 - tn: 75885.0000 - fn: 436.0000\n",
            "Epoch 34/41\n",
            "800/800 - 2s - loss: 0.0236 - auc: 0.9919 - pr: 0.9659 - precision: 0.9684 - recall: 0.8900 - tp: 3560.0000 - fp: 116.0000 - tn: 75884.0000 - fn: 440.0000\n",
            "Epoch 35/41\n",
            "800/800 - 2s - loss: 0.0236 - auc: 0.9918 - pr: 0.9659 - precision: 0.9682 - recall: 0.8905 - tp: 3562.0000 - fp: 117.0000 - tn: 75883.0000 - fn: 438.0000\n",
            "Epoch 36/41\n",
            "800/800 - 2s - loss: 0.0236 - auc: 0.9920 - pr: 0.9660 - precision: 0.9682 - recall: 0.8915 - tp: 3566.0000 - fp: 117.0000 - tn: 75883.0000 - fn: 434.0000\n",
            "Epoch 37/41\n",
            "800/800 - 2s - loss: 0.0236 - auc: 0.9918 - pr: 0.9659 - precision: 0.9685 - recall: 0.8913 - tp: 3565.0000 - fp: 116.0000 - tn: 75884.0000 - fn: 435.0000\n",
            "Epoch 38/41\n",
            "800/800 - 2s - loss: 0.0235 - auc: 0.9921 - pr: 0.9661 - precision: 0.9680 - recall: 0.8915 - tp: 3566.0000 - fp: 118.0000 - tn: 75882.0000 - fn: 434.0000\n",
            "Epoch 39/41\n",
            "800/800 - 2s - loss: 0.0235 - auc: 0.9919 - pr: 0.9660 - precision: 0.9682 - recall: 0.8903 - tp: 3561.0000 - fp: 117.0000 - tn: 75883.0000 - fn: 439.0000\n",
            "Epoch 40/41\n",
            "800/800 - 2s - loss: 0.0235 - auc: 0.9921 - pr: 0.9662 - precision: 0.9680 - recall: 0.8915 - tp: 3566.0000 - fp: 118.0000 - tn: 75882.0000 - fn: 434.0000\n",
            "Epoch 41/41\n",
            "800/800 - 2s - loss: 0.0235 - auc: 0.9919 - pr: 0.9661 - precision: 0.9680 - recall: 0.8913 - tp: 3565.0000 - fp: 118.0000 - tn: 75882.0000 - fn: 435.0000\n",
            "Retraining of the model #1\n",
            "Epoch 1/2\n",
            "800/800 - 3s - loss: 0.0821 - auc: 0.9644 - pr: 0.8490 - precision: 0.7495 - recall: 0.7922 - tp: 3169.0000 - fp: 1059.0000 - tn: 74941.0000 - fn: 831.0000\n",
            "Epoch 2/2\n",
            "800/800 - 2s - loss: 0.0590 - auc: 0.9678 - pr: 0.8704 - precision: 0.8848 - recall: 0.7415 - tp: 2966.0000 - fp: 386.0000 - tn: 75614.0000 - fn: 1034.0000\n",
            "Retraining of the model #2\n",
            "Epoch 1/32\n",
            "800/800 - 5s - loss: 0.0577 - auc: 0.9880 - pr: 0.9133 - precision: 0.9097 - recall: 0.8535 - tp: 3414.0000 - fp: 339.0000 - tn: 75661.0000 - fn: 586.0000\n",
            "Epoch 2/32\n",
            "800/800 - 4s - loss: 0.0250 - auc: 0.9917 - pr: 0.9621 - precision: 0.9646 - recall: 0.8850 - tp: 3540.0000 - fp: 130.0000 - tn: 75870.0000 - fn: 460.0000\n",
            "Epoch 3/32\n",
            "800/800 - 4s - loss: 0.0253 - auc: 0.9907 - pr: 0.9612 - precision: 0.9667 - recall: 0.8860 - tp: 3544.0000 - fp: 122.0000 - tn: 75878.0000 - fn: 456.0000\n",
            "Epoch 4/32\n",
            "800/800 - 4s - loss: 0.0248 - auc: 0.9914 - pr: 0.9629 - precision: 0.9625 - recall: 0.8863 - tp: 3545.0000 - fp: 138.0000 - tn: 75862.0000 - fn: 455.0000\n",
            "Epoch 5/32\n",
            "800/800 - 3s - loss: 0.0246 - auc: 0.9915 - pr: 0.9626 - precision: 0.9617 - recall: 0.8905 - tp: 3562.0000 - fp: 142.0000 - tn: 75858.0000 - fn: 438.0000\n",
            "Epoch 6/32\n",
            "800/800 - 4s - loss: 0.0247 - auc: 0.9909 - pr: 0.9628 - precision: 0.9637 - recall: 0.8890 - tp: 3556.0000 - fp: 134.0000 - tn: 75866.0000 - fn: 444.0000\n",
            "Epoch 7/32\n",
            "800/800 - 4s - loss: 0.0243 - auc: 0.9915 - pr: 0.9646 - precision: 0.9622 - recall: 0.8907 - tp: 3563.0000 - fp: 140.0000 - tn: 75860.0000 - fn: 437.0000\n",
            "Epoch 8/32\n",
            "800/800 - 4s - loss: 0.0250 - auc: 0.9924 - pr: 0.9621 - precision: 0.9668 - recall: 0.8892 - tp: 3557.0000 - fp: 122.0000 - tn: 75878.0000 - fn: 443.0000\n",
            "Epoch 9/32\n",
            "800/800 - 5s - loss: 0.0244 - auc: 0.9917 - pr: 0.9634 - precision: 0.9621 - recall: 0.8957 - tp: 3583.0000 - fp: 141.0000 - tn: 75859.0000 - fn: 417.0000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/32\n",
            "800/800 - 4s - loss: 0.0243 - auc: 0.9921 - pr: 0.9626 - precision: 0.9620 - recall: 0.8915 - tp: 3566.0000 - fp: 141.0000 - tn: 75859.0000 - fn: 434.0000\n",
            "Epoch 11/32\n",
            "800/800 - 4s - loss: 0.0240 - auc: 0.9917 - pr: 0.9642 - precision: 0.9598 - recall: 0.8953 - tp: 3581.0000 - fp: 150.0000 - tn: 75850.0000 - fn: 419.0000\n",
            "Epoch 12/32\n",
            "800/800 - 4s - loss: 0.0243 - auc: 0.9921 - pr: 0.9637 - precision: 0.9629 - recall: 0.8945 - tp: 3578.0000 - fp: 138.0000 - tn: 75862.0000 - fn: 422.0000\n",
            "Epoch 13/32\n",
            "800/800 - 4s - loss: 0.0242 - auc: 0.9913 - pr: 0.9638 - precision: 0.9633 - recall: 0.8932 - tp: 3573.0000 - fp: 136.0000 - tn: 75864.0000 - fn: 427.0000\n",
            "Epoch 14/32\n",
            "800/800 - 4s - loss: 0.0240 - auc: 0.9918 - pr: 0.9639 - precision: 0.9644 - recall: 0.8947 - tp: 3579.0000 - fp: 132.0000 - tn: 75868.0000 - fn: 421.0000\n",
            "Epoch 15/32\n",
            "800/800 - 4s - loss: 0.0240 - auc: 0.9924 - pr: 0.9645 - precision: 0.9657 - recall: 0.8873 - tp: 3549.0000 - fp: 126.0000 - tn: 75874.0000 - fn: 451.0000\n",
            "Epoch 16/32\n",
            "800/800 - 4s - loss: 0.0247 - auc: 0.9916 - pr: 0.9634 - precision: 0.9653 - recall: 0.8907 - tp: 3563.0000 - fp: 128.0000 - tn: 75872.0000 - fn: 437.0000\n",
            "Epoch 17/32\n",
            "800/800 - 4s - loss: 0.0239 - auc: 0.9919 - pr: 0.9646 - precision: 0.9711 - recall: 0.8900 - tp: 3560.0000 - fp: 106.0000 - tn: 75894.0000 - fn: 440.0000\n",
            "Epoch 18/32\n",
            "800/800 - 4s - loss: 0.0242 - auc: 0.9920 - pr: 0.9642 - precision: 0.9663 - recall: 0.8880 - tp: 3552.0000 - fp: 124.0000 - tn: 75876.0000 - fn: 448.0000\n",
            "Epoch 19/32\n",
            "800/800 - 4s - loss: 0.0235 - auc: 0.9929 - pr: 0.9654 - precision: 0.9639 - recall: 0.8940 - tp: 3576.0000 - fp: 134.0000 - tn: 75866.0000 - fn: 424.0000\n",
            "Epoch 20/32\n",
            "800/800 - 5s - loss: 0.0235 - auc: 0.9928 - pr: 0.9656 - precision: 0.9657 - recall: 0.8947 - tp: 3579.0000 - fp: 127.0000 - tn: 75873.0000 - fn: 421.0000\n",
            "Epoch 21/32\n",
            "800/800 - 4s - loss: 0.0237 - auc: 0.9925 - pr: 0.9650 - precision: 0.9645 - recall: 0.8907 - tp: 3563.0000 - fp: 131.0000 - tn: 75869.0000 - fn: 437.0000\n",
            "Epoch 22/32\n",
            "800/800 - 4s - loss: 0.0239 - auc: 0.9920 - pr: 0.9638 - precision: 0.9676 - recall: 0.8898 - tp: 3559.0000 - fp: 119.0000 - tn: 75881.0000 - fn: 441.0000\n",
            "Epoch 23/32\n",
            "800/800 - 4s - loss: 0.0240 - auc: 0.9922 - pr: 0.9643 - precision: 0.9673 - recall: 0.8867 - tp: 3547.0000 - fp: 120.0000 - tn: 75880.0000 - fn: 453.0000\n",
            "Epoch 24/32\n",
            "800/800 - 5s - loss: 0.0239 - auc: 0.9923 - pr: 0.9645 - precision: 0.9651 - recall: 0.8917 - tp: 3567.0000 - fp: 129.0000 - tn: 75871.0000 - fn: 433.0000\n",
            "Epoch 25/32\n",
            "800/800 - 5s - loss: 0.0239 - auc: 0.9929 - pr: 0.9649 - precision: 0.9663 - recall: 0.8898 - tp: 3559.0000 - fp: 124.0000 - tn: 75876.0000 - fn: 441.0000\n",
            "Epoch 26/32\n",
            "800/800 - 4s - loss: 0.0237 - auc: 0.9924 - pr: 0.9655 - precision: 0.9670 - recall: 0.8925 - tp: 3570.0000 - fp: 122.0000 - tn: 75878.0000 - fn: 430.0000\n",
            "Epoch 27/32\n",
            "800/800 - 4s - loss: 0.0237 - auc: 0.9922 - pr: 0.9646 - precision: 0.9690 - recall: 0.8907 - tp: 3563.0000 - fp: 114.0000 - tn: 75886.0000 - fn: 437.0000\n",
            "Epoch 28/32\n",
            "800/800 - 5s - loss: 0.0245 - auc: 0.9915 - pr: 0.9641 - precision: 0.9651 - recall: 0.8928 - tp: 3571.0000 - fp: 129.0000 - tn: 75871.0000 - fn: 429.0000\n",
            "Epoch 29/32\n",
            "800/800 - 5s - loss: 0.0238 - auc: 0.9930 - pr: 0.9649 - precision: 0.9679 - recall: 0.8892 - tp: 3557.0000 - fp: 118.0000 - tn: 75882.0000 - fn: 443.0000\n",
            "Epoch 30/32\n",
            "800/800 - 4s - loss: 0.0242 - auc: 0.9930 - pr: 0.9648 - precision: 0.9650 - recall: 0.8903 - tp: 3561.0000 - fp: 129.0000 - tn: 75871.0000 - fn: 439.0000\n",
            "Epoch 31/32\n",
            "800/800 - 4s - loss: 0.0235 - auc: 0.9921 - pr: 0.9656 - precision: 0.9628 - recall: 0.8935 - tp: 3574.0000 - fp: 138.0000 - tn: 75862.0000 - fn: 426.0000\n",
            "Epoch 32/32\n",
            "800/800 - 4s - loss: 0.0235 - auc: 0.9922 - pr: 0.9654 - precision: 0.9662 - recall: 0.8920 - tp: 3568.0000 - fp: 125.0000 - tn: 75875.0000 - fn: 432.0000\n"
          ]
        }
      ],
      "source": [
        "p_dict = {'batch_size': 100,  'validation_split': None, 'generator': bb_generator}\n",
        "trained, retrained = best_models_retraining(multituners_results, [X_train, y_train], p_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwnqK4WTW_oU",
        "outputId": "36a659f9-acf0-45d1-8101-126ff2e6a8f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(358.35162568092346,\n",
              " {'RandomSearch': (99.91610264778137,\n",
              "   (<keras_tuner.engine.hyperparameters.HyperParameters at 0x24bc63536a0>,\n",
              "    [<tensorflow.python.keras.engine.sequential.Sequential at 0x24bc6192b50>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc82bf7f0>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc389f7c0>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc5186b50>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc0df27f0>])),\n",
              "  'Hyperband': (106.95476770401001,\n",
              "   (<keras_tuner.engine.hyperparameters.HyperParameters at 0x24bc6997070>,\n",
              "    [<tensorflow.python.keras.engine.sequential.Sequential at 0x24bc4c63700>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bcb67abb0>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc6cc7ac0>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc1f66eb0>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc22c06d0>])),\n",
              "  'BayesianOptimization': (151.47964215278625,\n",
              "   (<keras_tuner.engine.hyperparameters.HyperParameters at 0x24bc6353370>,\n",
              "    [<tensorflow.python.keras.engine.sequential.Sequential at 0x24bc21afe80>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc4d35310>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc3a62730>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bc6546310>,\n",
              "     <tensorflow.python.keras.engine.sequential.Sequential at 0x24bcb6b0ee0>]))})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multituners_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0QsanEYW_oU",
        "outputId": "c72c16ca-5de0-403c-980d-616c657eb425"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[15426,  3574],\n",
              "       [  546,   454]], dtype=int64)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_model = dynamic_builder(multituners_results[1]['RandomSearch'][1][0])\n",
        "y_hat = rand_model.predict(X_test)\n",
        "confusion_matrix(y_test, y_hat > 0.5)\n",
        "# random_eval = best_random.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swdLGAcgW_oV",
        "outputId": "e2ce7d08-10c5-4783-9081-d30c062e9c58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[18962,    38],\n",
              "       [  120,   880]], dtype=int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rand_model = multituners_results[1]['RandomSearch'][1][1][0]\n",
        "y_hat = rand_model.predict(X_test)\n",
        "confusion_matrix(y_test, y_hat > 0.5)\n",
        "# random_eval = best_random.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YiQcxVYW_oW"
      },
      "outputs": [],
      "source": [
        "dic =  {'gen': 0}\n",
        "dic1 = {'gen': bb_generator}\n",
        "dic2 = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyS0oXCGW_oW",
        "outputId": "ba08082a-6d4f-4556-d14d-5e9d0ae75747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test: False, test: True, test: False\n"
          ]
        }
      ],
      "source": [
        "test = dic.get('gen', 0)\n",
        "test1 = dic1.get('gen', 0)\n",
        "test2 = dic2.get('gen', 0)\n",
        "print(f\"test: {test != 0}, test: {test1 != 0}, test: {test2 != 0}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}